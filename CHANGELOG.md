# Changelog

All notable changes to AI Studio will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

---

## [1.9.9.1] - 2025-10-21

### ğŸ”¥ Critical Dependency Fix - PEFT Library Missing

**Problem:** LoRA loading still failed with "PEFT backend is required for this method" error despite v1.9.9 code fix.

**Root Cause:** PEFT library was completely missing from `requirements.txt`!

**Why This Matters:**
- Even `fuse_lora()` and `unfuse_lora()` require PEFT internally
- Diffusers' LoRA implementation uses `peft.tuners.BaseTunerLayer` under the hood
- Without PEFT installed, ALL LoRA methods fail (including our v1.9.9 "PEFT-free" approach)

**Fixed:**
- âœ… Added `peft>=0.13.0` to `backend/requirements.txt`
- âœ… Updated installation documentation
- âœ… Version bumped to 1.9.9.1 across all files

**Installation Required:**
```bash
cd backend
pip install peft>=0.13.0
# Or reinstall all dependencies:
pip install -r requirements.txt
```

**Files Changed:**
- `backend/requirements.txt`: Added PEFT dependency
- `backend/config.py`: Version 1.9.9.1
- `frontend/package.json`: Version 1.9.9.1
- `frontend/src-tauri/Cargo.toml`: Version 1.9.9.1
- `frontend/src-tauri/tauri.conf.json`: Version 1.9.9.1
- `frontend/src/components/SettingsPanel.tsx`: Version 1.9.9.1
- `README.md`: Updated with v1.9.9.1 section

**Compatible Versions:**
```
diffusers==0.31.0
transformers==4.46.3
accelerate==1.1.1
peft>=0.13.0          # â† CRITICAL: Previously missing!
safetensors==0.4.5
```

---

## [1.9.9] - 2025-10-21

### ğŸ”¥ Critical LoRA Bugfix (Complete PEFT-Free Implementation)
- **FIXED: LoRA loading with Custom Models completely broken** - LoRAs caused PEFT errors
  - **Root Cause:** `load_lora_weights()` + `set_adapters()` requires PEFT backend
  - **Previous Fix (v1.9.6):** Incomplete - still called PEFT methods
  - **New Solution:** Complete rewrite using `fuse_lora()` method exclusively
  
### ğŸ¯ Technical Implementation

**Problem Analysis:**
```
ERROR: PEFT backend is required for this method.
- load_lora_weights() âœ… Works
- set_adapters() âŒ Requires PEFT
- unload_lora_weights() âŒ Requires PEFT
```

**New PEFT-Free Approach:**
```python
# OLD (v1.9.6-v1.9.8) - BROKEN
self.pipeline.load_lora_weights(dir, weight_name=file, adapter_name=name)
self.pipeline.set_adapters([name], adapter_weights=[weight])  # âŒ PEFT ERROR

# NEW (v1.9.9) - WORKS
self.pipeline.load_lora_weights(dir, weight_name=file)  # No adapter_name
self.pipeline.fuse_lora(lora_scale=weight)  # âœ… PEFT-FREE
```

**Changes:**
- `load_loras()`: Direct `fuse_lora()` after `load_lora_weights()`
- `unload_all_loras()`: Use `unfuse_lora()` instead of `unload_lora_weights()`
- Completely bypasses PEFT adapter system
- LoRAs are fused directly into pipeline weights

**Benefits:**
- âœ… No PEFT dependency
- âœ… Works with Custom Models
- âœ… Works with Standard Models
- âœ… Simpler code path
- âœ… Better logging

### ğŸ“ User Experience
- LoRAs laden ohne Fehler
- Custom Models + LoRAs funktionieren zusammen
- Keine PEFT-Warnungen mehr im Log

---

## [1.9.8] - 2025-10-21

### ğŸ”¥ Critical Bugfix (Custom Model Generation)
- **FIXED: Custom Model Generation nicht mÃ¶glich** - Bildgenerierung funktionierte nicht mit Custom Models
  - **Root Cause:** `currentModel` im App Store wurde nicht aktualisiert nach Custom Model laden
  - **Symptom:** Generate-Button validierte kein Model geladen â†’ blockierte Generierung
  - **Solution:** `setCurrentModel()` wird jetzt nach erfolgreichem Custom Model laden aufgerufen
  - File: `frontend/src/components/CustomModelList.tsx`
  
- **Model State Synchronization Improved**
  - Custom Model Info wird korrekt in App Store gespeichert
  - Format: `{ key: 'custom:ModelName', name, type, loaded: true, downloaded: true }`
  - ErmÃ¶glicht Generate-Button Validation
  
- **Standard Model Loading Enhanced**
  - Deaktiviert alle Custom Models beim Laden eines Standard-Models
  - Verhindert Konflikt zwischen Standard und Custom Models
  - File: `backend/api/routes.py` - `/models/load` endpoint

### ğŸ¯ Technical Details
**Frontend Changes:**
```typescript
// CustomModelList.tsx - handleLoadModel()
setCurrentModel({
  key: `custom:${model.name}`,
  name: model.name,
  type: model.model_type,
  loaded: true,
  downloaded: true
});
```

**Backend Changes:**
```python
# routes.py - load_model()
await db.deactivate_all_custom_models()  # Deactivate custom models when loading standard model
```

---

## [1.9.7] - 2025-10-21

### ğŸ› Bugfixes (UX Improvements)
- **Custom Model State Reset on Startup** - Behebt Problem dass Custom Models als "aktiv" angezeigt wurden nach App-Neustart
  - `backend/main.py`: Automatisches `deactivate_all_custom_models()` beim App-Start
  - Verhindert verwirrende UI-ZustÃ¤nde nach Neustart
  
- **Model Validation Before Generation** - Verhindert automatisches Laden von Standard-Models
  - `frontend/src/components/Header.tsx`: Model-Check vor Bildgenerierung
  - Zeigt Fehlermeldung: "Kein Model oder Custom Model geladen"
  - User muss explizit ein Model laden bevor er generieren kann
  
- **Image Generation Placeholders Fixed** - Placeholders werden jetzt korrekt angezeigt
  - `frontend/src/components/ImageGallery.tsx`: Conditional Rendering verbessert
  - Empty State nur wenn nicht generiert wird UND keine Bilder vorhanden
  - Placeholders werden wÃ¤hrend Generierung auch ohne vorherige Bilder angezeigt
  - Verhindert Ãœberlappung von Placeholders und generierten Bildern

### ğŸ¯ User Experience
- Klarere Kommunikation wenn kein Model geladen ist
- Konsistenter UI-Status nach App-Neustart
- Besseres visuelles Feedback wÃ¤hrend Bildgenerierung

---

## [1.9.6] - 2025-10-21

### ğŸ› Bugfixes (Critical LoRA Fix)
- **LoRA Loading Error Fixed** - "PEFT backend is required for this method" behoben
  - Umstellung auf moderne diffusers API ohne PEFT-AbhÃ¤ngigkeit
  - Fallback zu `fuse_lora()` fÃ¼r Systeme ohne PEFT Backend
  - Robusteres Error Handling beim LoRA-Laden und Entladen
  - UnterstÃ¼tzung fÃ¼r directory-based LoRA loading
- **LoRA Unloading Improved** - Graceful degradation bei fehlender PEFT-UnterstÃ¼tzung
  - Automatischer Fallback zu `unfuse_lora()` Methode
  - Bessere Fehlerbehandlung und Logging

### ğŸ”§ Technical Details
- File: `backend/core/model_manager.py`
- Method: `load_loras()` - Modernisiert ohne PEFT-Anforderung
- Method: `unload_all_loras()` - Fallback-Mechanismus hinzugefÃ¼gt
- KompatibilitÃ¤t: Funktioniert mit und ohne PEFT Backend

---

## [1.9.5] - 2025-01-21

### ğŸ‰ Features (UI/UX Improvements)
- **Toast Notifications** - Popup-Benachrichtigungen rechts oben beim Model-Laden
  - "Model wird geladen..." wÃ¤hrend des Ladens
  - "Fertig in VRAM geladen" fÃ¼r 3 Sekunden nach erfolgreichem Laden
  - Fehlerbenachrichtigungen bei Problemen
- **Image Generation Placeholders** - Live-Feedback wÃ¤hrend der Bildgenerierung
  - Zeigt Placeholder fÃ¼r jedes zu generierende Bild
  - Animierte Loading-Indikatoren mit Shimmer-Effekt
  - "Generiere Bild X..." Status-Text
- **Thumbnail Verification** - ÃœberprÃ¼fung der Custom Model Thumbnails
  - Korrekte Anzeige von Vorschaubildern
  - Fallback zu Icon bei fehlenden Thumbnails

### ğŸ”§ Frontend Components
- Component: `Toast.tsx` - Toast-Benachrichtigungssystem mit Slide-In-Animation
- Component: `ImagePlaceholder.tsx` - Placeholder fÃ¼r Bildgenerierung
- Store: Toast-State in `useAppStore` (showToast, hideToast)
- Integration: Toast in `SettingsPanel` und `CustomModelList`
- Integration: Placeholders in `ImageGallery`
- CSS: Slide-In und Shimmer-Animationen

### ğŸ“š Documentation
- Version: Updated to 1.9.5 in all config files
- CHANGELOG.md: v1.9.5 section added

---

## [1.9.0] - 2025-01-20

### ğŸ‰ Features (Custom Model Integration)
- **Custom Model Upload** - Eigene .safetensors Modelle hinzufÃ¼gen
- **Automatische Typ-Erkennung** - Erkennt SD1.5, SDXL, FLUX automatisch
- **PrÃ¤zisions-Support** - FP32, FP16, BF16, FP8 Safetensors unterstÃ¼tzt
- **Model Type Selection** - Manuelle Zuordnung mÃ¶glich (SD1.5, SDXL, Pony, etc.)
- **Optional Thumbnail** - Vorschaubilder fÃ¼r Custom Models
- **Custom Model Management** - Liste, LÃ¶schen, Aktivieren von Custom Models

### ğŸ”§ Backend
- Database: `custom_models` Tabelle fÃ¼r Custom Models
- API: `/api/custom-models` Endpoints (POST, GET, DELETE)
- API: `/api/custom-models/detect` - Auto-Detection von Model Type
- Utility: `model_detector.py` - Erkennt Model Typ aus Safetensors Metadata
- Support: Alle PrÃ¤zisionen (FP32/FP16/BF16/FP8)

### ğŸ¨ Frontend
- Component: `CustomModelAddForm` - Upload UI mit Auto-Detection
- Component: `CustomModelList` - Verwaltung der Custom Models
- Settings: Neuer "Custom Models" Tab
- File Picker: .safetensors + Thumbnail (PNG/JPG/WEBP)

### ğŸ“š Documentation
- CHANGELOG.md: v1.9.0 dokumentiert
- README.md: Custom Models Feature hinzugefÃ¼gt

---

## [1.8.0] - 2025-01-20

### ğŸ‰ Features (Major UI/UX Update)
- **History Copy-Funktion** - Einstellungen direkt aus History in Generate Ã¼bernehmen (Copy-Button)
- **Settings: Model Download Indicator** - GrÃ¼nes Licht zeigt heruntergeladene Modelle an
- **LoRA Strength erweitert** - Range von -1 bis +2 (statt 0-2) fÃ¼r mehr Kontrolle
- **NSFW Toggle** - Activate/Deactivate Button fÃ¼r NSFW-Content (Safety Checker)
- **Generate Button verlegt** - Jetzt prominent in Header-Mitte fÃ¼r bessere UX
- **Umbenennung zu "Astroburner-UI"** - Neuer Name im gesamten Projekt

### ğŸ”§ Changed
- Header: Generate-Button in die Mitte verlegt
- LoRA Weights: Negativer Range (-1.0 bis +2.0) fÃ¼r inverse LoRAs
- UI: Konsistentes "Astroburner-UI" Branding

### ğŸ“š Documentation
- README.md: Titel auf "Astroburner-UI" geÃ¤ndert
- package.json: Name auf "astroburner-ui-frontend"
- Tauri Config: Product Name & Identifier aktualisiert

---

## [1.7.5] - 2025-01-20

### ğŸ› Fixed (Critical Bugfixes)
- **LoRA Durchsuchen-Button defekt** - Dialog Plugin jetzt voll funktionsfÃ¤hig
- **LoRAs verschwinden nach Refresh** - Auto-Reload alle Sekunde implementiert
- **History: Positiv-Prompt wird abgeschnitten** - VollstÃ¤ndige Anzeige mit word-wrap
- **History: Seed wird nicht angezeigt** - Seeds werden jetzt korrekt angezeigt (oder "Random")
- **Prompt-Textareas passen sich nicht an** - Auto-Resize basierend auf TextlÃ¤nge

### ğŸ”§ Changed
- README.md: Fokus auf setup.bat, manuelle Installation in CONTRIBUTING.md
- README.md: Voraussetzungen klar definiert (Python, Node.js, Git, Rust, Visual Studio Build Tools)
- README.md: Installation vereinfacht - nur setup.bat erklÃ¤rt
- README.md: GitHub Link hinzugefÃ¼gt

---

## [1.7.1] - 2025-01-20

### ğŸ†• Added
- **11 neue Modelle:**
  - Pony Diffusion XL V6 - Anthropomorphe Charaktere (âœ… Ready)
  - Illustrious XL - High-Quality Anime (âœ… Ready)
  - FLUX.1 Dev - State-of-the-art T2I (ğŸš§ Experimentell)
  - FLUX.1 Kontext Dev - Image Editing (ğŸš§ Experimentell)
  - Wan 2.1 T2V/I2V - Video Generation (ğŸš§ Experimentell)
  - Wan 2.2 T2V/I2V/S2V - Enhanced Video (ğŸš§ Experimentell)
  - Qwen-Image/Edit - Text Rendering (ğŸš§ Experimentell)
- Dialog Plugin fÃ¼r File Picker (Tauri)
- CUDA Auto-Detection fÃ¼r RTX 5090/4090/3090
- Automatischer CUDA-Fix in setup.bat
- `ADVANCED_MODELS_ARCHITECTURE.md` - Technische Dokumentation
- `NEW_MODELS_v1.7.1.md` - Modell-Ãœbersicht
- GitHub Issue Templates
- CONTRIBUTING.md

### ğŸ”§ Changed
- `sentencepiece` Version: `==0.2.0` â†’ `>=0.2.1`
- Backend Version: 1.6.0 â†’ 1.7.1
- Frontend Version: 1.6.0 â†’ 1.7.1
- setup.bat: EnableDelayedExpansion Syntax korrigiert
- README.md: Status-Icons fÃ¼r Modelle (âœ…/ğŸš§)

### ğŸ› Fixed
- Dialog Plugin Import Error im Frontend
- Pydantic `model_type` namespace Warnung
- Batch-Datei Syntax-Fehler mit "."
- PyTorch CPU-Installation statt CUDA
- Port 3000 Konflikt-Management

### âš ï¸ Known Issues
- FLUX/Wan/Qwen benÃ¶tigen spezielle Konfiguration (siehe ADVANCED_MODELS_ARCHITECTURE.md)
- Video-Generierung ist experimentell und sehr langsam
- FLUX benÃ¶tigt Hugging Face Login

---

## [1.6.0] - 2025-01-15

### ğŸ†• Added
- Text-to-Image Generation mit mehreren Parametern
- Image-to-Image mit Denoise Strength Control
- Multi-Model Support (SD1.5, SDXL, SDXL-Turbo)
- Complete LoRA Management (bis zu 5 gleichzeitig)
- Individual LoRA Strength Control (0.0-2.0)
- GPU Management mit VRAM Monitoring
- Enhanced History Panel
- Modern Dark UI mit Tailwind CSS
- Lazy Model Loading
- SQLite Database fÃ¼r Metadata

### ğŸ”§ Changed
- Complete UI Redesign
- Performance Optimierungen
- VRAM Management verbessert

---

## [1.5.0] - 2025-01-10

### ğŸ†• Added
- Erstes Ã¶ffentliches Release
- SD1.5 Support
- SDXL Support
- Basic UI

---

## Roadmap

### [1.8.0] - Geplant
- âœ… VollstÃ¤ndige FLUX.1 Integration mit T5-XXL
- âœ… Wan-VAE automatischer Download
- âœ… Qwen korrekte Pipeline
- âœ… Spezielle Pipeline-Loader
- âœ… VRAM-Check vor Model-Loading
- âœ… UI-Warnungen fÃ¼r groÃŸe Downloads

### [2.0.0] - Zukunft
- âœ… Video-Tab mit Timeline-Editor
- âœ… Quantization-Support (8-bit/4-bit)
- âœ… Model-Varianten (FLUX schnell/dev/pro)
- âœ… ControlNet Support
- âœ… Inpainting & Outpainting
- âœ… Batch Processing

---

**Legend:**
- ğŸ†• Added - Neue Features
- ğŸ”§ Changed - Ã„nderungen an existierenden Features
- ğŸ› Fixed - Bug Fixes
- âš ï¸ Known Issues - Bekannte Probleme
- ğŸ—‘ï¸ Removed - Entfernte Features
