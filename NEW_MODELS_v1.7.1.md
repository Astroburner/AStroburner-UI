# AI Studio v1.7.1 - New Models Documentation

## üéâ Neue Modelle

AI Studio v1.7.1 f√ºgt **11 neue Modelle** hinzu, die verschiedene Stile und Anwendungsf√§lle abdecken:

---

## üìã Modell√ºbersicht

### **1. Pony Diffusion XL V6** üê¥
- **Model ID:** `LyliaEngine/Pony_Diffusion_V6_XL`
- **Typ:** Text-to-Image (SDXL-basiert)
- **Spezialisierung:** Anime, Furry, Anthro-Charaktere
- **VRAM:** 8-12 GB
- **Aufl√∂sung:** 1024x1024 (native SDXL)
- **Besonderheiten:**
  - Hervorragend f√ºr anthropomorphe Charaktere
  - SFW und NSFW Inhalte m√∂glich
  - Sehr detailliert bei Fell/Texturen
- **Empfohlene Settings:**
  - Steps: 25-35
  - Guidance Scale: 7.0-8.5
  - Scheduler: Euler Ancestral

---

### **2. Illustrious XL** ‚ú®
- **Model ID:** `OnomaAIResearch/Illustrious-xl-early-release-v0`
- **Typ:** Text-to-Image (SDXL-basiert)
- **Spezialisierung:** High-Quality Anime/Illustration
- **VRAM:** 8-12 GB
- **Aufl√∂sung:** 1024x1024
- **Besonderheiten:**
  - Fortsetzung von Kohaku XL Beta 5
  - Sehr sauberer, heller Anime-Stil
  - Ausgezeichnete Charakterkonsistenz
- **Empfohlene Settings:**
  - Steps: 28-40
  - Guidance Scale: 7.0-9.0
  - Scheduler: DPM++ 2M Karras

---

### **3. FLUX.1 Dev** üåä
- **Model ID:** `black-forest-labs/FLUX.1-dev`
- **Typ:** Text-to-Image
- **Spezialisierung:** Hochaufl√∂sende, realistische Bilder
- **VRAM:** 24+ GB (sehr gro√ü!)
- **Aufl√∂sung:** Variable (bis 2048x2048)
- **Besonderheiten:**
  - 12 Milliarden Parameter
  - Rectified Flow Transformer
  - State-of-the-art Qualit√§t
  - **WICHTIG:** Gated Model - Hugging Face Login erforderlich!
- **Empfohlene Settings:**
  - Steps: 20-30
  - Guidance Scale: 3.5-5.0
  - Scheduler: Euler

---

### **4. FLUX.1 Kontext Dev** üé®
- **Model ID:** `black-forest-labs/FLUX.1-Kontext-dev`
- **Typ:** Image-to-Image (Text-gesteuert)
- **Spezialisierung:** Bildbearbeitung nach Anweisungen
- **VRAM:** 24+ GB
- **Aufl√∂sung:** Variable
- **Besonderheiten:**
  - Instruction-based Image Editing
  - Kann Bilder gezielt nach Textanweisungen ver√§ndern
  - Sehr pr√§zise Kontrolle
  - **WICHTIG:** Gated Model - Hugging Face Login erforderlich!
- **Empfohlene Settings:**
  - Steps: 20-30
  - Guidance Scale: 3.5-5.0
  - Denoise Strength: 0.5-0.8

---

### **5. Wan 2.1 T2V 14B** üé¨
- **Model ID:** `Wan-AI/Wan2.1-T2V-14B`
- **Typ:** Text-to-Video
- **Spezialisierung:** Video-Generierung aus Text
- **VRAM:** 16+ GB
- **Aufl√∂sung:** 480p, 720p
- **Besonderheiten:**
  - 14 Milliarden Parameter
  - Hochwertige Video-Generierung
  - Unterst√ºtzt beide Aufl√∂sungen
  - Alibaba Open-Source Model
- **Hinweis:**
  - Video-Generierung ist experimentell
  - Kann mehrere Minuten pro Video dauern
  - Spezielle Pipeline-Konfiguration erforderlich

---

### **6. Wan 2.1 I2V 14B** üñºÔ∏è‚û°Ô∏èüé¨
- **Model ID:** `Wan-AI/Wan2.1-I2V-14B`
- **Typ:** Image-to-Video
- **Spezialisierung:** Video-Generierung aus Einzelbild
- **VRAM:** 16+ GB
- **Aufl√∂sung:** 480p, 720p
- **Besonderheiten:**
  - Animiert statische Bilder zu Videos
  - Hochwertige Bewegungsgenerierung
  - Konsistente Charakterdarstellung
- **Hinweis:**
  - Ben√∂tigt Eingabebild
  - Video-Generierung ist experimentell

---

### **7. Wan 2.2 T2V 14B** üé¨
- **Model ID:** `Wan-AI/Wan2.2-T2V-14B`
- **Typ:** Text-to-Video
- **Spezialisierung:** Verbesserte Video-Generierung aus Text
- **VRAM:** 16+ GB
- **Aufl√∂sung:** 480p, 720p
- **Besonderheiten:**
  - Neueste Wan-Version (2.2)
  - Bessere Qualit√§t als 2.1
  - Schnellere Inferenz
  - Verbesserte Bewegungsqualit√§t
- **Hinweis:**
  - Empfohlen gegen√ºber Wan 2.1 T2V
  - Experimentelle Unterst√ºtzung

---

### **8. Wan 2.2 I2V 14B** üñºÔ∏è‚û°Ô∏èüé¨
- **Model ID:** `Wan-AI/Wan2.2-I2V-14B`
- **Typ:** Image-to-Video
- **Spezialisierung:** Verbesserte Bild-zu-Video-Konvertierung
- **VRAM:** 16+ GB
- **Aufl√∂sung:** 480p, 720p
- **Besonderheiten:**
  - Neueste I2V-Version
  - Nat√ºrlichere Bewegungen
  - Bessere Charakterkonsistenz
- **Hinweis:**
  - Empfohlen gegen√ºber Wan 2.1 I2V
  - Ben√∂tigt Eingabebild

---

### **9. Wan 2.2 S2V 14B** üé§
- **Model ID:** `Wan-AI/Wan2.2-S2V-14B`
- **Typ:** Speech-to-Video
- **Spezialisierung:** Audio-gesteuerte Video-Generierung
- **VRAM:** 16+ GB
- **Aufl√∂sung:** 480p, 720p
- **Besonderheiten:**
  - Generiert Videos aus Audiodateien
  - Ideal f√ºr Digital Humans / Talking Heads
  - Neueste Version (2.2)
  - Cinematic Video Generation
- **Hinweis:**
  - Ben√∂tigt Audioeingabe (.wav, .mp3)
  - Experimentelles Feature

---

### **10. Qwen-Image** üñºÔ∏è
- **Model ID:** `Qwen/Qwen-Image`
- **Typ:** Text-to-Image
- **Spezialisierung:** Komplexe Text-Rendering, Poster
- **VRAM:** 8-16 GB
- **Aufl√∂sung:** Variable
- **Besonderheiten:**
  - Exzellentes Text-Rendering im Bild
  - Gut f√ºr Poster/Designs mit Text
  - Unterst√ºtzt Chinesisch und Englisch
  - Apache 2.0 Lizenz
- **Empfohlene Settings:**
  - Steps: 25-35
  - Guidance Scale: 7.0-9.0

---

### **11. Qwen-Image Edit** ‚úèÔ∏è
- **Model ID:** `Qwen/Qwen-Image` (gleiche Basis wie Qwen-Image)
- **Typ:** Image-to-Image
- **Spezialisierung:** Pr√§zise Bildbearbeitung
- **VRAM:** 8-16 GB
- **Aufl√∂sung:** Variable
- **Besonderheiten:**
  - Instruction-based Editing
  - Kann Text in Bildern bearbeiten
  - Sehr pr√§zise Kontrolle
- **Empfohlene Settings:**
  - Steps: 20-30
  - Denoise Strength: 0.6-0.8

---

## üîß Technische Details

### **Pipeline-Kompatibilit√§t:**

| Modell | Pipeline-Typ | Basis |
|--------|-------------|-------|
| Pony Diffusion XL | StableDiffusionXLPipeline | SDXL |
| Illustrious XL | StableDiffusionXLPipeline | SDXL |
| FLUX.1 Dev | DiffusionPipeline | Flux |
| FLUX.1 Kontext | DiffusionPipeline | Flux |
| Wan 2.1 T2V | DiffusionPipeline | Wan |
| Wan 2.1 I2V | DiffusionPipeline | Wan |
| Wan 2.2 T2V | DiffusionPipeline | Wan |
| Wan 2.2 I2V | DiffusionPipeline | Wan |
| Wan 2.2 S2V | DiffusionPipeline | Wan |
| Qwen-Image | DiffusionPipeline | Qwen |
| Qwen-Image Edit | DiffusionPipeline | Qwen |

### **VRAM-Anforderungen:**

- **SDXL-basiert (Pony, Illustrious):** 8-12 GB
- **Flux-basiert:** 24+ GB (sehr gro√ü!)
- **Wan-basiert:** 16+ GB
- **Qwen-basiert:** 8-16 GB

---

## üì¶ Installation

### **1. Backend Dependencies aktualisieren:**

```bash
cd backend
venv\Scripts\activate
pip install -r requirements.txt
```

**Neue Dependencies in v1.7.1:**
- `sentencepiece==0.2.0` - F√ºr Qwen Tokenizers
- `protobuf==5.28.3` - F√ºr Qwen und Flux Models

### **2. Hugging Face Login (f√ºr Flux):**

Flux-Modelle sind "gated" und ben√∂tigen Login:

```bash
huggingface-cli login
```

**Oder in Python:**
```python
from huggingface_hub import login
login(token="your_hf_token_here")
```

Token erstellen: https://huggingface.co/settings/tokens

---

## üé® Verwendung in AI Studio

### **Modell laden:**

1. √ñffne AI Studio
2. Gehe zu "Models" Tab
3. W√§hle das gew√ºnschte Modell:
   - **SD1.5** - Original Stable Diffusion
   - **SDXL** - Stable Diffusion XL
   - **SDXL-Turbo** - Schnelle SDXL-Variante
   - **Pony** - Anthropomorphe Charaktere
   - **Illustrious** - High-Quality Anime
   - **Flux-Dev** - Hochaufl√∂sende Bilder
   - **Flux-Kontext** - Bildbearbeitung
   - **Wan2.1** - Video-Generierung
   - **Wan2.2** - Audio-to-Video
   - **Qwen** - Text-Rendering
   - **Qwen-image-edit** - Bildbearbeitung

### **LoRAs mit neuen Modellen:**

LoRAs sind kompatibel mit:
- ‚úÖ **SD1.5** - SD1.5 LoRAs
- ‚úÖ **SDXL** - SDXL LoRAs
- ‚úÖ **Pony** - SDXL LoRAs (optimiert f√ºr Pony)
- ‚úÖ **Illustrious** - SDXL LoRAs (optimiert f√ºr Illustrious)
- ‚ùå **Flux** - Keine Standard-LoRA-Unterst√ºtzung (eigenes System)
- ‚ùì **Wan** - Video-LoRAs (experimentell)
- ‚ùì **Qwen** - Experimentell

**Wichtig:** W√§hle den richtigen "Model Type" beim LoRA-Hinzuf√ºgen!

---

## ‚ö†Ô∏è Bekannte Einschr√§nkungen

### **Flux-Modelle:**
- Sehr gro√ü (24+ GB VRAM)
- Erfordern Hugging Face Login
- Langsamer als SDXL
- Keine Standard-LoRA-Unterst√ºtzung

### **Video-Modelle (Wan):**
- Experimentelle Unterst√ºtzung
- Sehr langsam (mehrere Minuten pro Video)
- Hoher VRAM-Bedarf
- UI noch nicht vollst√§ndig f√ºr Video optimiert

### **Qwen-Modelle:**
- Ben√∂tigen spezielle Tokenizer
- Chinesische/Englische Prompts bevorzugt
- Bildbearbeitung experimentell

---

## üöÄ Performance-Tipps

### **F√ºr RTX 5090:**
- ‚úÖ Alle Modelle funktionieren
- ‚úÖ FLUX.1 l√§uft fl√ºssig (24 GB VRAM)
- ‚úÖ Video-Generierung m√∂glich
- ‚ö° Empfohlene Settings:
  - `enable_xformers=True`
  - `enable_attention_slicing=True`
  - `vae_slicing=True`

### **F√ºr RTX 4090 (24 GB):**
- ‚úÖ Alle SDXL-Modelle
- ‚úÖ FLUX.1 l√§uft (knapp)
- ‚ö†Ô∏è Video-Generierung langsam
- ‚ö° Nutze kleinere Batch Sizes

### **F√ºr RTX 3090 (24 GB):**
- ‚úÖ SDXL-Modelle
- ‚ö†Ô∏è FLUX.1 sehr knapp
- ‚ùå Video-Generierung schwierig
- ‚ö° Nutze aggressive VRAM-Optimierungen

### **F√ºr GPUs < 24 GB:**
- ‚úÖ SD1.5, SDXL, Pony, Illustrious
- ‚ùå FLUX.1 (zu gro√ü)
- ‚ùå Video-Generierung (zu gro√ü)
- ‚ö° Fokus auf SDXL-basierte Modelle

---

## üìö Weiterf√ºhrende Links

- **Pony Diffusion:** https://civitai.com/models/257749
- **Illustrious:** https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0
- **FLUX.1:** https://huggingface.co/black-forest-labs
- **Wan:** https://github.com/Wan-Video
- **Qwen:** https://github.com/QwenLM/Qwen-Image

---

## üêõ Troubleshooting

### **"Model not found" Fehler:**
```bash
# Cache l√∂schen und neu herunterladen
rm -rf models/
python main.py  # L√§dt Modell automatisch neu
```

### **"Out of memory" bei Flux:**
```python
# In config.py:
ENABLE_ATTENTION_SLICING = True
VAE_SLICING = True
```

### **Hugging Face Login Fehler:**
```bash
huggingface-cli login
# Token eingeben: hf_...
```

### **Video-Generierung h√§ngt:**
- Normal! Videos dauern 5-10 Minuten
- Pr√ºfe GPU-Auslastung mit `nvidia-smi`
- Kleinere Aufl√∂sung w√§hlen (480p statt 720p)

---

**Version:** v1.7.1  
**Datum:** 2025-01-20  
**Status:** Experimentelle Unterst√ºtzung f√ºr Video-Modelle
