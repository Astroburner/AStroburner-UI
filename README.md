# AI Studio - Desktop AI Generation App

Eine moderne Desktop-Anwendung fÃ¼r KI-basierte Bild- und Videogenerierung mit lokalem GPU-Support.

![AI Studio](https://img.shields.io/badge/version-1.2.0-blue)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey)
![License](https://img.shields.io/badge/license-MIT-green)

## ğŸ¯ Features

### MVP (Version 1.0)
- âœ… **Text-to-Image Generation** mit mehreren Parametern
- âœ… **Multi-Model Support** (SD1.5, SDXL, SDXL-Turbo)
- âœ… **GPU Management** mit VRAM Monitoring
- âœ… **Gallery System** mit History & Metadata
- âœ… **Modern Dark UI** mit Tailwind CSS
- âœ… **Lazy Model Loading** fÃ¼r optimierte Performance
- âœ… **SQLite Database** fÃ¼r Metadata & History

### Geplant (Future)
- ğŸ”„ Text-to-Video Generation (Wan Model)
- ğŸ”„ LoRA Support
- ğŸ”„ Inpainting & Outpainting
- ğŸ”„ Batch Processing
- ğŸ”„ Model Download Manager

## ğŸ—ï¸ Tech Stack

### Frontend
- **Framework:** Tauri 2.0 (Rust + Web)
- **UI Library:** React 18 + TypeScript
- **Styling:** Tailwind CSS
- **State Management:** Zustand
- **Icons:** React Icons

### Backend
- **Framework:** FastAPI (Python)
- **ML Framework:** PyTorch + Diffusers
- **Database:** SQLite (aiosqlite)
- **GPU Support:** CUDA (NVIDIA), MPS (Apple Silicon)

## ğŸ“‹ Voraussetzungen

### Hardware
- **GPU:** NVIDIA GPU mit CUDA Support (empfohlen 6GB+ VRAM)
  - Alternativ: Apple Silicon (MPS) oder CPU (langsam)
- **RAM:** Mindestens 16GB (32GB empfohlen)
- **Speicher:** 20GB+ freier Speicherplatz fÃ¼r Models

### Software
- **Windows:** Windows 10/11 (64-bit)
- **macOS:** macOS 11+ (Apple Silicon oder Intel)
- **Linux:** Ubuntu 20.04+ oder Ã¤quivalent

#### FÃ¼r Entwicklung:
- Node.js 18+ & npm
- Python 3.10+
- Rust 1.70+ (fÃ¼r Tauri)
- Git

## ğŸš€ Schnellstart (Windows)

### âš¡ Automatische Installation (Empfohlen!)

**NEU in v1.2.0**: Ein einziger Befehl installiert alles automatisch!

```cmd
# 1. Download und entpacken
# https://page.gensparksite.com/project_backups/ai-studio-v1.2.0-interactive-setup.tar.gz

# 2. Automatische Installation (15-25 Min)
cd ai-studio
setup.bat

# 3. WÃ¤hle deine GPU wÃ¤hrend der Installation:
#    Option 1: RTX 5090 / RTX 50-series (CUDA 12.8)
#    Option 2: RTX 4090 / RTX 40-series (CUDA 12.1)
#    Option 3: RTX 3090 / RTX 30-series (CUDA 11.8)
#    Option 4: CPU only
```

**Das war's! ğŸ‰** Nach der Installation zeigt setup.bat ein interaktives MenÃ¼ mit Quick Actions.

**Siehe:** [SETUP_BAT_README.md](SETUP_BAT_README.md) fÃ¼r Details

---

### ğŸ“– Manuelle Installation

Falls du setup.bat nicht nutzen mÃ¶chtest, folge dieser Anleitung:

### 1. Repository Klonen

```bash
git clone https://github.com/yourusername/ai-studio.git
cd ai-studio
```

### 2. Backend Setup (Python)

```bash
cd backend

# Virtual Environment erstellen
python -m venv venv

# Aktivieren:
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Dependencies installieren
pip install -r requirements.txt

# PyTorch Installation (wÃ¤hle basierend auf deiner GPU):

# CUDA 12.8 (RTX 5090, RTX 50-series):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128

# CUDA 12.1 (RTX 4090, RTX 40-series):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8 (RTX 3090, RTX 30-series):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# MPS Support (Apple Silicon M1/M2/M3):
pip install torch torchvision

# CPU Only (fallback):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### 3. Frontend Setup (React + Tauri)

```bash
cd ../frontend

# Node Dependencies installieren
npm install

# Rust Dependencies (Tauri CLI)
npm install --save-dev @tauri-apps/cli
```

### 4. Environment Variables (optional)

Erstelle `.env` im Backend-Ordner:

```env
# Backend/.env
DEBUG=True
API_HOST=127.0.0.1
API_PORT=8000
DEVICE=cuda  # cuda, mps, oder cpu
```

## ğŸ® Anwendung Starten

### Development Mode

**Terminal 1 - Backend starten:**
```bash
cd backend
source venv/bin/activate  # oder venv\Scripts\activate auf Windows
python main.py
```

Backend lÃ¤uft auf: `http://127.0.0.1:8000`

**Terminal 2 - Frontend starten:**
```bash
cd frontend
npm run tauri dev
```

Die Desktop-App Ã¶ffnet sich automatisch!

### Production Build

```bash
cd frontend
npm run tauri build
```

Die fertige App findest du in: `frontend/src-tauri/target/release/`

## ğŸ“– Verwendung

### Erste Schritte

1. **App starten** - Backend und Frontend mÃ¼ssen beide laufen
2. **Model laden** - Gehe zu Settings â†’ Models â†’ "SDXL Turbo" laden (schnellstes Model)
3. **Prompt eingeben** - Beschreibe was du generieren mÃ¶chtest
4. **Parameter anpassen** - Width, Height, Steps, Guidance Scale
5. **Generate** - Klicke "Bild Generieren"

### Parameter ErklÃ¤rung

- **Width/Height:** BildgrÃ¶ÃŸe (512x512 = schnell, 1024x1024 = hochauflÃ¶send)
- **Steps:** Anzahl Diffusions-Steps (20-30 = schnell, 50+ = hohe QualitÃ¤t)
- **Guidance Scale:** Wie stark der Prompt befolgt wird (7-8 = ausgewogen, 12+ = sehr streng)
- **Seed:** FÃ¼r reproduzierbare Ergebnisse (leer = random)

### Empfohlene Einstellungen

**Schnelle Generierung:**
- Model: SDXL-Turbo
- Size: 512x512
- Steps: 4-8
- Guidance: 0-1

**Hohe QualitÃ¤t:**
- Model: SDXL Base
- Size: 1024x1024
- Steps: 30-50
- Guidance: 7-8

## ğŸ—‚ï¸ Projektstruktur

```
ai-studio/
â”œâ”€â”€ backend/                 # Python FastAPI Backend
â”‚   â”œâ”€â”€ api/                # API Routes
â”‚   â”œâ”€â”€ core/               # Core Funktionen (GPU, Model Manager)
â”‚   â”œâ”€â”€ models/             # Database Models
â”‚   â”œâ”€â”€ utils/              # Utilities
â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”œâ”€â”€ main.py             # FastAPI App Entry
â”‚   â””â”€â”€ requirements.txt    # Python Dependencies
â”‚
â”œâ”€â”€ frontend/               # React + Tauri Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React Components
â”‚   â”‚   â”œâ”€â”€ hooks/         # Custom Hooks (Zustand Store)
â”‚   â”‚   â”œâ”€â”€ services/      # API Service
â”‚   â”‚   â”œâ”€â”€ types/         # TypeScript Types
â”‚   â”‚   â””â”€â”€ styles/        # Tailwind CSS
â”‚   â”œâ”€â”€ src-tauri/         # Tauri Rust Backend
â”‚   â”‚   â”œâ”€â”€ src/          # Rust Source
â”‚   â”‚   â””â”€â”€ tauri.conf.json
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ models/                 # AI Models (auto-downloaded)
â”œâ”€â”€ outputs/                # Generated Images
â”œâ”€â”€ ai_studio.db           # SQLite Database
â””â”€â”€ README.md
```

## ğŸ› Troubleshooting

### Backend startet nicht

**Problem:** `ModuleNotFoundError: No module named 'torch'`
```bash
# Virtual Environment aktivieren!
source venv/bin/activate  # oder venv\Scripts\activate
pip install -r requirements.txt
```

**Problem:** CUDA nicht gefunden
```bash
# Check CUDA Installation:
nvidia-smi

# PyTorch mit CUDA neu installieren:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### Frontend baut nicht

**Problem:** Tauri CLI fehlt
```bash
npm install --save-dev @tauri-apps/cli
```

**Problem:** Rust fehlt
- Installiere Rust: https://rustup.rs/

### Models downloaden langsam

- Models werden beim ersten Laden automatisch von HuggingFace heruntergeladen
- SDXL Base: ~6.9GB
- SDXL Turbo: ~6.9GB
- SD 1.5: ~4GB

Cache Location: `models/` Ordner

### VRAM Fehler (Out of Memory)

**LÃ¶sung 1:** Kleinere BildgrÃ¶ÃŸe verwenden (512x512)
**LÃ¶sung 2:** Weniger Steps (20-30)
**LÃ¶sung 3:** Settings â†’ GPU Cache Leeren

## ğŸ”§ API Dokumentation

Backend API lÃ¤uft auf: `http://127.0.0.1:8000`

### Endpoints

- `GET /api/health` - Health Check
- `GET /api/gpu/info` - GPU Informationen
- `POST /api/gpu/clear-cache` - GPU Cache leeren
- `GET /api/models` - VerfÃ¼gbare Models auflisten
- `POST /api/models/load` - Model laden
- `POST /api/generate/image` - Bild generieren
- `GET /api/history` - Generation History
- `GET /api/stats` - Statistiken

API Docs: http://127.0.0.1:8000/docs (Swagger UI)

## ğŸ“Š Performance

### Benchmark (NVIDIA RTX 3080)

| Model | Size | Steps | Time |
|-------|------|-------|------|
| SD 1.5 | 512x512 | 30 | ~8s |
| SDXL Base | 1024x1024 | 30 | ~25s |
| SDXL Turbo | 512x512 | 4 | ~2s |

## ğŸ¤ Contributing

Contributions sind willkommen! Bitte erstelle ein Issue oder Pull Request.

## ğŸ“ License

MIT License - siehe LICENSE Datei

## ğŸ‘¤ Autor

**Astroburner**
- YouTube: [@Astroburner-AI](https://www.youtube.com/@Astroburner-AI)

## ğŸ™ Credits

- Stable Diffusion by Stability AI
- Diffusers by HuggingFace
- Tauri Framework
- React & Tailwind CSS

---

**Viel SpaÃŸ beim Generieren! ğŸ¨âœ¨**
