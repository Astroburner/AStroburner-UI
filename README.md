# AI Studio - Desktop AI Generation App

Eine moderne Desktop-Anwendung fÃ¼r KI-basierte Bild- und Videogenerierung mit lokalem GPU-Support.

![AI Studio](https://img.shields.io/badge/version-1.7.1-blue)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey)
![License](https://img.shields.io/badge/license-MIT-green)

## âš ï¸ WICHTIG: Nach dem Entpacken

**Backup enthÃ¤lt keine `node_modules` um DateigrÃ¶ÃŸe zu reduzieren!**

### Quick-Fix (Sollte CUDA nicht erkannt werden):
```bash
quick-fix-dependencies.bat
```

### Oder mit Setup-Script:
```bash
setup.bat
```

Siehe auch: [INSTALL_AFTER_EXTRACT.md](INSTALL_AFTER_EXTRACT.md)

## ğŸ¯ Features

### v1.7.1 Features (NEU!)
- ğŸ†• **11 neue Modelle hinzugefÃ¼gt:**
  - **Pony Diffusion XL V6** âœ… - Anthropomorphe Charaktere (SDXL-kompatibel)
  - **Illustrious XL** âœ… - High-Quality Anime (SDXL-kompatibel)
  - **FLUX.1 Dev** ğŸš§ - HochauflÃ¶sende Bilder (24GB VRAM, spezielle Architektur)
  - **FLUX.1 Kontext Dev** ğŸš§ - Instruction-based Image Editing (spezielle Architektur)
  - **Wan 2.1 T2V 14B** ğŸš§ - Text-to-Video Generation (experimentell)
  - **Wan 2.1 I2V 14B** ğŸš§ - Image-to-Video Generation (experimentell)
  - **Wan 2.2 T2V 14B** ğŸš§ - Enhanced Text-to-Video (experimentell)
  - **Wan 2.2 I2V 14B** ğŸš§ - Enhanced Image-to-Video (experimentell)
  - **Wan 2.2 S2V 14B** ğŸš§ - Speech-to-Video Generation (experimentell)
  - **Qwen-Image** ğŸš§ - Text-Rendering & Poster (spezielle Architektur)
  - **Qwen-Image Edit** ğŸš§ - PrÃ¤zise Bildbearbeitung (spezielle Architektur)
- âœ… **LoRA Support** fÃ¼r alle SDXL-basierten Modelle (SD1.5, SDXL, Pony, Illustrious)
- âœ… **Automatische Dialog Plugin Integration** fÃ¼r File-Picker
- âœ… **CUDA Auto-Detection & Auto-Fix** fÃ¼r RTX 5090

**âš ï¸ WICHTIGER HINWEIS:** FLUX, Wan und Qwen verwenden **spezielle Architekturen** mit eigenen VAEs, Text Encodern und Komponenten. Siehe `ADVANCED_MODELS_ARCHITECTURE.md` fÃ¼r Details. Diese Modelle benÃ¶tigen manuelle Konfiguration in v1.7.1!

### v1.6.0 Features
- âœ… **Text-to-Image Generation** mit mehreren Parametern
- âœ… **Image-to-Image** mit Denoise Strength Control
- âœ… **Multi-Model Support** (SD1.5, SDXL, SDXL-Turbo)
- âœ… **Complete LoRA Management** (bis zu 5 gleichzeitig)
- âœ… **Individual LoRA Strength Control** (0.0-2.0)
- âœ… **GPU Management** mit VRAM Monitoring
- âœ… **Enhanced History Panel** mit Scheduler & Denoise Display
- âœ… **Modern Dark UI** mit Tailwind CSS
- âœ… **Lazy Model Loading** fÃ¼r optimierte Performance
- âœ… **SQLite Database** fÃ¼r Metadata & History

### Geplant (Future)
- ğŸ”„ Text-to-Video Generation (Wan Model)
- ğŸ”„ Inpainting & Outpainting
- ğŸ”„ ControlNet Support
- ğŸ”„ Batch Processing
- ğŸ”„ Model Download Manager

## ğŸ—ï¸ Tech Stack

### Frontend
- **Framework:** Tauri 2.0 (Rust + Web)
- **UI Library:** React 18 + TypeScript
- **Styling:** Tailwind CSS
- **State Management:** Zustand
- **Icons:** React Icons

### Backend
- **Framework:** FastAPI (Python)
- **ML Framework:** PyTorch + Diffusers
- **Database:** SQLite (aiosqlite)
- **GPU Support:** CUDA (NVIDIA), MPS (Apple Silicon)

## ğŸ“‹ Voraussetzungen

### Hardware
- **GPU:** NVIDIA GPU mit CUDA Support (empfohlen 6GB+ VRAM)
  - Alternativ: Apple Silicon (MPS) oder CPU (langsam)
- **RAM:** Mindestens 16GB (32GB empfohlen)
- **Speicher:** 20GB+ freier Speicherplatz fÃ¼r Models

### Software
- **Windows:** Windows 10/11 (64-bit)
- **macOS:** macOS 11+ (Apple Silicon oder Intel)
- **Linux:** Ubuntu 20.04+ oder Ã¤quivalent

#### FÃ¼r Entwicklung:
- Node.js 18+ & npm
- Python 3.10+
- Rust 1.70+ (fÃ¼r Tauri)
- Git

## ğŸš€ Schnellstart (Windows)

### âš¡ Automatische Installation (Empfohlen!)

**NEU in v1.6.0**: Ein einziger Befehl installiert alles automatisch - **inkl. automatischer CUDA-Verifizierung und Reparatur!**

```cmd
# 1. Download und entpacken
# https://github.com/Astroburner/AStroburner-UI.git

# 2. Automatische Installation (15-25 Min)
cd ai-studio
setup.bat

# 3. WÃ¤hle deine GPU wÃ¤hrend der Installation:
#    Option 1: RTX 5090 / RTX 50-series (CUDA 12.8) [AUTO-DETECTED]
#    Option 2: RTX 4090 / RTX 40-series (CUDA 12.1)
#    Option 3: RTX 3090 / RTX 30-series (CUDA 11.8)
#    Option 4: CPU only
```

**NEU: Automatische CUDA-ÃœberprÃ¼fung!** ğŸ”¥
- Setup.bat erkennt automatisch deine GPU (RTX 5090)
- Installiert die korrekte CUDA-Version (12.8)
- Verifiziert nach Installation automatisch, ob CUDA funktioniert
- **Falls CUDA nicht funktioniert:** Automatischer Fix ohne Benutzereingriff!
- **App-Start nur mÃ¶glich, wenn CUDA erfolgreich verifiziert wurde**

**Das war's! ğŸ‰** Nach der Installation zeigt setup.bat ein interaktives MenÃ¼ mit Quick Actions.

**Siehe:** [SETUP_BAT_README.md](SETUP_BAT_README.md) fÃ¼r Details

---

### ğŸ“– Manuelle Installation

Falls du setup.bat nicht nutzen mÃ¶chtest, folge dieser Anleitung:

### 1. Repository Klonen

```bash
git clone https://github.com/Astroburner/AStroburner-UI.git
cd ai-studio
```

### 2. Backend Setup (Python)

```bash
cd backend

# Virtual Environment erstellen
python -m venv venv

# Aktivieren:
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Dependencies installieren
pip install -r requirements.txt

# PyTorch Installation (wÃ¤hle basierend auf deiner GPU):

# CUDA 12.8 (RTX 5090, RTX 50-series):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128

# CUDA 12.1 (RTX 4090, RTX 40-series):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8 (RTX 3090, RTX 30-series):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# MPS Support (Apple Silicon M1/M2/M3):
pip install torch torchvision

# CPU Only (fallback):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### 3. Frontend Setup (React + Tauri)

```bash
cd ../frontend

# Node Dependencies installieren
npm install

# Rust Dependencies (Tauri CLI)
npm install --save-dev @tauri-apps/cli
```

### 4. Environment Variables (optional)

Erstelle `.env` im Backend-Ordner:

```env
# Backend/.env
DEBUG=True
API_HOST=127.0.0.1
API_PORT=8000
DEVICE=cuda  # cuda, mps, oder cpu
```

## ğŸ® Anwendung Starten

### Development Mode

**Terminal 1 - Backend starten:**
```bash
cd backend
source venv/bin/activate  # oder venv\Scripts\activate auf Windows
python main.py
```

Backend lÃ¤uft auf: `http://127.0.0.1:8000`

**Terminal 2 - Frontend starten:**
```bash
cd frontend
npm run tauri dev
```

Die Desktop-App Ã¶ffnet sich automatisch!

### Production Build

```bash
cd frontend
npm run tauri build
```

Die fertige App findest du in: `frontend/src-tauri/target/release/`

## ğŸ“– Verwendung

### Erste Schritte

1. **App starten** - Backend und Frontend mÃ¼ssen beide laufen
2. **Model laden** - Gehe zu Settings â†’ Models â†’ "SDXL Turbo" laden (schnellstes Model)
3. **Prompt eingeben** - Beschreibe was du generieren mÃ¶chtest
4. **Parameter anpassen** - Width, Height, Steps, Guidance Scale
5. **Generate** - Klicke "Bild Generieren"

### Parameter ErklÃ¤rung

- **Width/Height:** BildgrÃ¶ÃŸe (512x512 = schnell, 1024x1024 = hochauflÃ¶send)
- **Steps:** Anzahl Diffusions-Steps (20-30 = schnell, 50+ = hohe QualitÃ¤t)
- **Guidance Scale:** Wie stark der Prompt befolgt wird (7-8 = ausgewogen, 12+ = sehr streng)
- **Seed:** FÃ¼r reproduzierbare Ergebnisse (leer = random)

### Empfohlene Einstellungen

**Schnelle Generierung:**
- Model: SDXL-Turbo
- Size: 512x512
- Steps: 4-8
- Guidance: 0-1

**Hohe QualitÃ¤t:**
- Model: SDXL Base
- Size: 1024x1024
- Steps: 30-50
- Guidance: 7-8

## ğŸ—‚ï¸ Projektstruktur

```
ai-studio/
â”œâ”€â”€ backend/                 # Python FastAPI Backend
â”‚   â”œâ”€â”€ api/                # API Routes
â”‚   â”œâ”€â”€ core/               # Core Funktionen (GPU, Model Manager)
â”‚   â”œâ”€â”€ models/             # Database Models
â”‚   â”œâ”€â”€ utils/              # Utilities
â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”œâ”€â”€ main.py             # FastAPI App Entry
â”‚   â””â”€â”€ requirements.txt    # Python Dependencies
â”‚
â”œâ”€â”€ frontend/               # React + Tauri Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React Components
â”‚   â”‚   â”œâ”€â”€ hooks/         # Custom Hooks (Zustand Store)
â”‚   â”‚   â”œâ”€â”€ services/      # API Service
â”‚   â”‚   â”œâ”€â”€ types/         # TypeScript Types
â”‚   â”‚   â””â”€â”€ styles/        # Tailwind CSS
â”‚   â”œâ”€â”€ src-tauri/         # Tauri Rust Backend
â”‚   â”‚   â”œâ”€â”€ src/          # Rust Source
â”‚   â”‚   â””â”€â”€ tauri.conf.json
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ models/                 # AI Models (auto-downloaded)
â”œâ”€â”€ outputs/                # Generated Images
â”œâ”€â”€ ai_studio.db           # SQLite Database
â””â”€â”€ README.md
```

## ğŸ› Troubleshooting

### Backend startet nicht

**Problem:** `ModuleNotFoundError: No module named 'torch'`
```bash
# Virtual Environment aktivieren!
source venv/bin/activate  # oder venv\Scripts\activate
pip install -r requirements.txt
```

**Problem:** CUDA nicht gefunden
```bash
# Check CUDA Installation:
nvidia-smi

# PyTorch mit CUDA neu installieren:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### Frontend baut nicht

**Problem:** Tauri CLI fehlt
```bash
npm install --save-dev @tauri-apps/cli
```

**Problem:** Rust fehlt
- Installiere Rust: https://rustup.rs/

### Models downloaden langsam

- Models werden beim ersten Laden automatisch von HuggingFace heruntergeladen
- SDXL Base: ~6.9GB
- SDXL Turbo: ~6.9GB
- SD 1.5: ~4GB

Cache Location: `models/` Ordner

### VRAM Fehler (Out of Memory)

**LÃ¶sung 1:** Kleinere BildgrÃ¶ÃŸe verwenden (512x512)
**LÃ¶sung 2:** Weniger Steps (20-30)
**LÃ¶sung 3:** Settings â†’ GPU Cache Leeren

## ğŸ”§ API Dokumentation

Backend API lÃ¤uft auf: `http://127.0.0.1:8000`

### Endpoints

- `GET /api/health` - Health Check
- `GET /api/gpu/info` - GPU Informationen
- `POST /api/gpu/clear-cache` - GPU Cache leeren
- `GET /api/models` - VerfÃ¼gbare Models auflisten
- `POST /api/models/load` - Model laden
- `POST /api/generate/image` - Bild generieren
- `GET /api/history` - Generation History
- `GET /api/stats` - Statistiken

API Docs: http://127.0.0.1:8000/docs (Swagger UI)

## ğŸ“Š Performance

### Benchmark (NVIDIA RTX 3080)

| Model | Size | Steps | Time |
|-------|------|-------|------|
| SD 1.5 | 512x512 | 30 | ~8s |
| SDXL Base | 1024x1024 | 30 | ~25s |
| SDXL Turbo | 512x512 | 4 | ~2s |

## ğŸ¤ Contributing

Contributions sind willkommen! Bitte erstelle ein Issue oder Pull Request.

## ğŸ“ License

MIT License - siehe LICENSE Datei

## ğŸ‘¤ Autor

**Astroburner**
- YouTube: [@Astroburner-AI](https://www.youtube.com/@Astroburner-AI)

## ğŸ™ Credits

- Stable Diffusion by Stability AI
- Diffusers by HuggingFace
- Tauri Framework
- React & Tailwind CSS

---

**Viel SpaÃŸ beim Generieren! ğŸ¨âœ¨**
