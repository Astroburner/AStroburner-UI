# NSFW Filter Kontrolle

## Problem

Standardm√§√üig hat Stable Diffusion einen NSFW (Not Safe For Work) Content Filter, der potenziell unangemessene Inhalte blockiert.

**Symptom:**
```
Potential NSFW content was detected in one or more images. 
A black image will be returned instead. 
Try again with a different prompt and/or seed.
```

Das f√ºhrt zu schwarzen Bildern anstatt der generierten Inhalte.

---

## L√∂sung - Filter deaktivieren

### ‚úÖ Standardm√§√üig DEAKTIVIERT in AI Studio

**Der NSFW-Filter ist standardm√§√üig ausgeschaltet** in diesem Projekt.

**Warum?**
- Du hast volle Kontrolle √ºber deine Generierungen
- Keine False Positives (z.B. Strand, Kunst, Anatomie)
- F√ºr professionelle/k√ºnstlerische Anwendungen
- Du bist selbst verantwortlich f√ºr deine Prompts

---

## Konfiguration

### Option 1: In config.py (Permanent)

**Datei:** `backend/config.py`

```python
class Settings(BaseSettings):
    # ...
    
    # Content Filtering
    DISABLE_NSFW_FILTER: bool = True  # Filter AUS
    # DISABLE_NSFW_FILTER: bool = False  # Filter AN
```

**√Ñndern:**
```python
# Filter EINSCHALTEN (schwarze Bilder bei NSFW):
DISABLE_NSFW_FILTER: bool = False

# Filter AUSSCHALTEN (alle Inhalte erlauben):
DISABLE_NSFW_FILTER: bool = True  # ‚Üê Standard
```

**Nach √Ñnderung:**
- Backend neu starten: `python main.py`
- Beim Model-Laden wird die neue Einstellung angewendet

---

### Option 2: Mit .env Datei (Flexibel)

**Erstelle:** `backend/.env`

```env
# AI Studio Configuration

# NSFW Filter Control
DISABLE_NSFW_FILTER=true   # Filter aus (Standard)
# DISABLE_NSFW_FILTER=false  # Filter an
```

**Vorteile:**
- Keine Code-√Ñnderung n√∂tig
- Einfach zwischen Einstellungen wechseln
- .env wird von Git ignoriert (nicht committed)

**Nach √Ñnderung:**
- Backend neu starten
- Neue Einstellung wird geladen

---

## Wie der Filter funktioniert

### Technische Details

**Mit Filter (safety_checker aktiv):**
```python
pipeline = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    safety_checker=<SafetyChecker>,  # Pr√ºft jedes Bild
    requires_safety_checker=True
)
```

**Ohne Filter (AI Studio Standard):**
```python
pipeline = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    safety_checker=None,  # Keine Pr√ºfung
    requires_safety_checker=False
)
```

### Was der Filter erkennt

**Der NSFW-Filter pr√ºft auf:**
- Nacktheit
- Explizite Inhalte
- Gewalt
- Andere unangemessene Inhalte

**Problem:** Viele False Positives!
- Strand-Szenen
- Kunst (Skulpturen, Gem√§lde)
- Medizinische Illustrationen
- Fitness/Sport
- Anatomie-Studien

**Deshalb standardm√§√üig deaktiviert in AI Studio.**

---

## √úberpr√ºfen der aktuellen Einstellung

### Im Backend Log

**Beim Model-Laden:**
```
INFO: Loading model: Stable Diffusion XL
INFO: NSFW filter disabled (safety_checker=None)  ‚Üê Filter AUS
INFO: Model loaded successfully
```

oder

```
INFO: Loading model: Stable Diffusion XL
INFO: NSFW filter enabled  ‚Üê Filter AN
INFO: Model loaded successfully
```

### Im Code √ºberpr√ºfen

```python
# backend/test_nsfw.py
from config import settings

print(f"NSFW Filter: {'DISABLED' if settings.DISABLE_NSFW_FILTER else 'ENABLED'}")
```

```cmd
cd backend
venv\Scripts\activate
python test_nsfw.py
```

---

## Empfehlungen

### F√ºr Privat/Hobby:
**Filter AUS** (Standard)
- Volle kreative Freiheit
- Keine √úberraschungen mit schwarzen Bildern
- Du entscheidest selbst

### F√ºr Kommerziell/√ñffentlich:
**Filter AN**
- Sicherer f√ºr Arbeitsumgebungen
- Vermeidet unangemessene Inhalte
- F√ºr √∂ffentliche Demos/Pr√§sentationen

### F√ºr Kunst/Professionell:
**Filter AUS**
- K√ºnstlerische Freiheit
- Anatomie-Studien m√∂glich
- Keine Zensur von Kunst

---

## Alternative: Manueller Prompt-Filter

**Statt technischem Filter, verwende selbst Negative Prompts:**

```python
# Prompt
"A beautiful landscape..."

# Negative Prompt (was du NICHT willst)
"nsfw, nude, naked, explicit, adult content, sexual, 
 inappropriate, violence, gore, disturbing"
```

**Vorteile:**
- Du hast volle Kontrolle
- Keine False Positives
- Flexibler als automatischer Filter

---

## H√§ufige Fragen

### Q: Ist es legal, den Filter zu deaktivieren?

**A:** Ja, vollkommen legal. Du nutzt die Software privat auf deinem eigenen Computer. Du bist selbst verantwortlich f√ºr die Inhalte, die du generierst.

### Q: Welche Risiken gibt es?

**A:** 
- **Keine technischen Risiken** - Software funktioniert identisch
- **Inhaltliche Verantwortung liegt bei dir** - Nutze die Software verantwortungsvoll
- **F√ºr kommerzielle Nutzung:** Pr√ºfe Lizenzvereinbarungen der Models

### Q: Kann ich den Filter f√ºr einzelne Prompts aktivieren/deaktivieren?

**A:** Aktuell nur global in config.py. 

**Zuk√ºnftig geplant:** UI-Toggle f√ºr Filter pro Generierung.

### Q: Was passiert wenn Filter aktiviert ist und NSFW erkannt wird?

**A:** 
- Backend gibt schwarzes Bild zur√ºck
- Log zeigt: "Potential NSFW content detected"
- Keine Fehlermeldung, einfach schwarzes Ergebnis
- L√∂sung: Prompt √§ndern oder Filter deaktivieren

---

## Code-Referenz

### Model Manager mit Filter-Logik

**Datei:** `backend/core/model_manager.py`

```python
# Configure NSFW filter based on settings
pipeline_kwargs = {
    "torch_dtype": self.dtype,
    "use_safetensors": True,
    "cache_dir": settings.MODELS_DIR
}

# Disable NSFW filter if configured
if settings.DISABLE_NSFW_FILTER:
    pipeline_kwargs["safety_checker"] = None
    pipeline_kwargs["requires_safety_checker"] = False
    logger.info("NSFW filter disabled (safety_checker=None)")
else:
    logger.info("NSFW filter enabled")

self.pipeline = pipeline_class.from_pretrained(
    model_info["model_id"],
    **pipeline_kwargs
)
```

---

## Zusammenfassung

**Standard in AI Studio:**
‚úÖ **NSFW Filter ist DEAKTIVIERT**

**Warum:**
- Volle kreative Kontrolle
- Keine False Positives
- Professionelle/k√ºnstlerische Anwendungen

**√Ñndern wenn n√∂tig:**
1. `backend/config.py` ‚Üí `DISABLE_NSFW_FILTER = False`
2. Backend neu starten
3. Oder `.env` Datei nutzen

**Empfehlung:**
- Filter aus f√ºr private/k√ºnstlerische Nutzung
- Filter an f√ºr √∂ffentliche/kommerzielle Umgebungen
- Nutze Negative Prompts f√ºr granulare Kontrolle

---

**Du hast jetzt volle Kontrolle √ºber den Content-Filter! üé®**
